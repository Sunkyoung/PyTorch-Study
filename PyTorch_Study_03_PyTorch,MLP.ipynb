{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunkyoung/PyTorch-Study/blob/main/PyTorch_Study_03_PyTorch%2CMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKpknpnXe3QF"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1vC0N3Obk4HZJk9JOG7fKgYE10YYlCqsg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi4aew0He3QG"
      },
      "source": [
        "# Week 3: PyTorch, Logistic Regression and MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0jyeP1ne3QG"
      },
      "source": [
        "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
        "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
        "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n",
        "\n",
        "If you have any questions, feel free to ask\n",
        "- For additional questions, post questions in classum or send emails to jihoontack@kaist.ac.kr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY3e4une3QG"
      },
      "source": [
        "## Why PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qwXu3Ype3QH"
      },
      "source": [
        "- Intuitive and concise code\n",
        "- Define by Run method (Tensorflow is Define and Run method)\n",
        "- High compatibility with Numpy (almost one-to-one mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj_lrocge3QH"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdTJwbVxe3QH"
      },
      "source": [
        "## 0. Prelim: Load packages & GPU setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kSQhqVSYe3QH",
        "outputId": "24ad0571-e469-4aa8-a472-948267193f15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 10:19:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# visualize current GPU usages in your server\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JFcCAJNle3QJ"
      },
      "outputs": [],
      "source": [
        "# set gpu by number\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Cqcw-roge3QK"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BG2ANdIie3QK",
        "outputId": "e59d50e7-1c91-49f3-ffc1-7b8d96b8062c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "# print the version of PyTorch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaJJdkAxe3QK"
      },
      "source": [
        "## 1. PyTorch and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHbrQGPZe3QK"
      },
      "source": [
        "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
        "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
        "**Almost the same with Numpy array**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mujSI777e3QL"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92fm_8hte3QL"
      },
      "source": [
        "### PyTorch and Numpy shares almost identical grammer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QPtMwgBe3QL"
      },
      "source": [
        "\n",
        "**We will show some examples of:**\n",
        "- Same operation with identical grammer\n",
        "- Same operation with different grammer\n",
        "- Different operation with same grammer\n",
        "\n",
        "**We will not handle all examples in this class :(**\n",
        "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vl0-U2Ge3QL"
      },
      "source": [
        "**First! Define Numpy array and PyTorch tensor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2wkd_2XPe3QL",
        "outputId": "35a1fdc2-78f2-4e51-c164-471a68a41596",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4]\n",
            "[5 6 7 8]\n",
            "tensor([1, 2, 3, 4])\n",
            "tensor([5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "np_array_1 = np.array([1, 2, 3, 4])\n",
        "np_array_2 = np.array([5, 6, 7, 8])\n",
        "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
        "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
        "\n",
        "print (np_array_1)\n",
        "print (np_array_2)\n",
        "print (torch_tensor_1)\n",
        "print (torch_tensor_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDJMceNye3QL"
      },
      "source": [
        "**1) Same operations with identical grammer**\n",
        "\n",
        "Example) Get the shape of the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AXdGgPtZe3QM",
        "outputId": "060a5b9f-f784-4083-e192-8c85fab2b9ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "print(np_array_1.shape)\n",
        "\n",
        "# torch\n",
        "print(torch_tensor_1.shape)\n",
        "# size() and shape operation is identical in torch\n",
        "print(torch_tensor_1.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPasZWqNe3QM"
      },
      "source": [
        "**2) Same operations with different grammer**\n",
        "\n",
        "Example 1) Concatenate two tensors\n",
        "- numpy use `np.concatenate`\n",
        "- torch use `torch.cat`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RumdJr0Te3QM",
        "outputId": "edc48045-4b7f-4e97-8568-54d84f1ff288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[1 2 3 4 5 6 7 8]\n",
            "----torch----\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_concat = np.concatenate([np_array_1, np_array_2], axis=0)\n",
        "print('----numpy----')\n",
        "print(np_concat)\n",
        "\n",
        "# torch\n",
        "torch_concat = torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
        "print('----torch----')\n",
        "print(torch_concat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBhHnoape3QM"
      },
      "source": [
        "Example 2) reshape the tensor shape\n",
        "- numpy use `X.reshape`\n",
        "- torch use `X.view`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VYqBKahVe3QM",
        "outputId": "c6cf9b93-004d-4858-cd00-4831e3ed3241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]]\n",
            "(4, 2)\n",
            "----torch----\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_reshaped = np_concat.reshape(4, 2)\n",
        "print('----numpy----')\n",
        "print(np_reshaped)\n",
        "print(np_reshaped.shape)\n",
        "\n",
        "# torch\n",
        "torch_reshaped = torch_concat.view(4, 2)\n",
        "print('----torch----')\n",
        "print(torch_reshaped)\n",
        "print(torch_reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84jU135Fe3QN"
      },
      "source": [
        "**3) Different operations with same grammer (Confusing operations)**\n",
        "\n",
        "Example) manipulation tensors\n",
        "- Same grammer `repeat`  has different operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "T2Lp-wlYe3QN",
        "outputId": "6104dd32-2b9c-44bb-e39e-4c74836eddba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[1 2 3]\n",
            "[1 1 1 2 2 2 3 3 3]\n",
            "----torch----\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
            "tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3])\n",
        "x_repeat = x.repeat(3)\n",
        "\n",
        "print('----numpy----')\n",
        "print(x)\n",
        "print(x_repeat)\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(3)\n",
        "\n",
        "print('----torch----')\n",
        "print(x)\n",
        "print(x_repeat)\n",
        "\n",
        "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
        "x_repeat = x.repeat_interleave(3)\n",
        "print(x_repeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "22A6kMyie3QN",
        "outputId": "3a14b3e9-2304-4534-8f22-e8d0d4b05fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n"
          ]
        }
      ],
      "source": [
        "# similar manipulation operation: stack & repeat\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(4)\n",
        "x_stack = torch.stack([x, x, x, x])\n",
        "\n",
        "print (x_repeat)\n",
        "print (x_stack)\n",
        "print (x_repeat.view(4, 3)) # reshape x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDH-Ah8ke3QO"
      },
      "source": [
        "## 2. Tensor operations under GPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IOnn2JIe3QO"
      },
      "source": [
        "Deep learning frameworks utilize GPUs to accelarate computations.\n",
        "\n",
        "In this section, we will learn **how to utilize GPU** in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "j3PRYIrYe3QO",
        "outputId": "4414d3b6-b062-4397-acc8-299999069e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())  # Is GPU accessible?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "i0eGH0Bue3QP"
      },
      "outputs": [],
      "source": [
        "a = torch.ones(3)\n",
        "b = torch.randn(100, 50, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "exPfAzzxe3QP",
        "outputId": "04b66dfc-958c-4c7d-b573-06a97f46f108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7fwI9w0ce3QP"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9yfVMRXve3QQ",
        "outputId": "b89c2477-df3b-49e3-be5c-744efad644e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "e1Mjpxvae3QQ"
      },
      "outputs": [],
      "source": [
        "# upload a and b to GPU\n",
        "# .to('cuda') is identical to .cuda()\n",
        "a = a.to('cuda') # a.cuda()\n",
        "b = b.to('cuda') # b.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = a.cuda()\n",
        "b = b.cuda()"
      ],
      "metadata": {
        "id": "HAwvBtN0-3PC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1eZq_e9me3QQ",
        "outputId": "eee4fabb-1263-4c00-c36c-ef0563a012ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xJQip49qe3QQ"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SBJF9JFOe3QQ",
        "outputId": "a0798368-46dd-4867-e291-7f69c585f146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dQTTu3afe3QR"
      },
      "outputs": [],
      "source": [
        "c = c.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7sGX9tHge3QR",
        "outputId": "d2fae0b4-41c3-460a-ad95-575e220a1e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aIwO2de3QR"
      },
      "source": [
        "## 3. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofgXYf4Je3QS"
      },
      "source": [
        "Central to all neural networks in PyTorch is the `autograd` package. \n",
        "\n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_wjab0Ye3QS"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_OiNIdp0e3QS",
        "outputId": "36ef0210-62b7-4704-d5aa-026235cc534d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "waF1GbGge3QS",
        "outputId": "9657de08-a0ce-49c5-e04c-31092b8b9064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4tmO65yQe3QS",
        "outputId": "fe3c9e75-5e9d-4007-d8fa-0be5ffa926bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Mh5UkK_5e3QS",
        "outputId": "803c735f-6050-4348-b618-cfe17806959d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = z.mean()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "htoLcUrQe3QT"
      },
      "outputs": [],
      "source": [
        "# retrain grad for y, z. backward for out\n",
        "y.retain_grad()\n",
        "z.retain_grad()\n",
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ZWKUkae3QT"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n",
        "![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dtfH7VhDe3QT",
        "outputId": "4456fe6a-091f-4880-8d67-0298f4475a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "print(z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-y-XgIae3QT"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n",
        "![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mt-2jk49e3QT",
        "outputId": "2e58b625-9134-46fb-e05a-61607674f17c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5pCoFHge3QT"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n",
        "![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Nnz-IJSJe3QU",
        "outputId": "622f6aac-c7d8-459c-efa5-1e538a782ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8_PJXSqe3QU"
      },
      "source": [
        "### Efficient inference (testing) with torch.no_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE9A3Rn-e3QU"
      },
      "source": [
        "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
        "\n",
        "Situation: when **gradient calculation is not required** e.g., inference\\\n",
        "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Arj23J6Ze3QU"
      },
      "outputs": [],
      "source": [
        "# gradient calculation is not required\n",
        "with torch.no_grad():\n",
        "    x = torch.ones(2, 2, requires_grad=True)\n",
        "    y = x + 2\n",
        "    z = y * y * 3\n",
        "    out = z.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "SA_mzzbQe3QU",
        "outputId": "2b10a687-f68b-4732-89f4-ca136679c1dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "24IfBrFse3QU",
        "outputId": "3323935e-476a-49ba-b035-e3d470678e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-bf3332dd1f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## ERROR!!!!: we used torch.no_grad()!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVL7zZ-6e3QU"
      },
      "source": [
        "## 4. nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LynWY12We3QV"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEQM-1xze3QV"
      },
      "source": [
        "### Using pre-defined modules (subset of models) in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xMr0FtFme3QV",
        "outputId": "4435431f-cd76-43a8-a94a-637d3c8e5c21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "\n",
        "print(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "iMtTe-02e3QV"
      },
      "outputs": [],
      "source": [
        "# input dim 3, output dim 1\n",
        "linear_fn = nn.Linear(3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "x-94MouQe3QV",
        "outputId": "b08357ea-436e-47dc-efd7-268c959909bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "linear_fn  # WX + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Yf_S-iyBe3QV",
        "outputId": "27011781-7589-4421-e7ef-5f05d0a048ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7191],\n",
            "        [-0.3344]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ],
      "source": [
        "Y = linear_fn(X)\n",
        "print(Y)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jFBcYlUse3QV",
        "outputId": "9911c7b8-0428-4634-cdf6-48b2895d8179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.0535, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "Y = Y.sum()\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzSkVzhre3QW"
      },
      "source": [
        "You can use other types of `nn.Module` in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "pNK2YHQZe3QW"
      },
      "outputs": [],
      "source": [
        "nn.Conv2d\n",
        "nn.RNNCell\n",
        "nn.LSTMCell\n",
        "nn.GRUCell\n",
        "nn.Transformer;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjkgHy5Ee3QW"
      },
      "source": [
        "### How can we design a customized model (neural network)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "KB1OwFpUe3QW"
      },
      "outputs": [],
      "source": [
        "# Linear -> ReLU -> Linear\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu()\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbu2BzbIe3QW"
      },
      "source": [
        "**What is activation function?**\n",
        "- They make non-linearity for deep neural networks\n",
        "- Therefore, deep neural networks can approximate complex functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y41RVjGHe3QW"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1dxJJUOzYykRfW2q3my2Qtg82RsjptIx4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XtDdAAEue3QW"
      },
      "outputs": [],
      "source": [
        "nn.Sigmoid\n",
        "nn.ReLU\n",
        "nn.LeakyReLU\n",
        "nn.Tanh;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GzgRLa3e3QW"
      },
      "source": [
        "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bEUw0ACe3QW"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1kdig6RLSCvYJNqarbb8gviYsnxZfSkYQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3jkmw_Ce3QX"
      },
      "source": [
        "### What is MNIST & How to do multi-class classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxVM0qxSe3QX"
      },
      "source": [
        "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
        "\n",
        "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbf49gt1e3QX"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q82CHBv9e3QX"
      },
      "source": [
        "### Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OKNbO3iVe3QX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rX5b-8Fe3QX"
      },
      "source": [
        "### Load datasets for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DnFlcJEOe3QX"
      },
      "outputs": [],
      "source": [
        "# Download MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "# mini batch size : 128 for train, 100 for test\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwtNrO-Ke3QX"
      },
      "source": [
        "### Define model (we will use one layer classifier first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ_br-lqe3QX"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Xe4J88NglbuASnfYJYI7ISqA1c1rcs5P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PgK-2QWme3QY"
      },
      "outputs": [],
      "source": [
        "# Define model class\n",
        "# This model has one hidden layer\n",
        "class Multinomial_logistic_regression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "      super(Multinomial_logistic_regression, self).__init__()\n",
        "      self.linear = nn.Linear(input_size, output_size)\n",
        "    def forward(self, x):\n",
        "      out = self.linear(x)\n",
        "      return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rUuZ-9a8e3QY"
      },
      "outputs": [],
      "source": [
        "# Generate model\n",
        "# input dim: 784  / output dim: 10\n",
        "model = Multinomial_logistic_regression(784, 10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ivF3VpOVe3QY",
        "outputId": "9c0092bb-e066-43de-a7c9-0cef4a642495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Multinomial_logistic_regression(\n",
              "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uNoe2lhPe3QY"
      },
      "outputs": [],
      "source": [
        "# Upload model to GPU \n",
        "model = model.to('cuda') #.cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_pRvvppe3QY"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2x-Z8KYe3QY"
      },
      "source": [
        "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
        "\n",
        "PyTorch optimizer is about **which optimization methods to use for training**\n",
        "\n",
        "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tr0ZMS67e3QY"
      },
      "outputs": [],
      "source": [
        "# Optimizer define\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpzJA9Me3QY"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssTGUfwMe3QY"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZPwCCFIRe3QZ",
        "outputId": "b2378587-d846-4556-9672-8e5f6ee8f1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.3782\n",
            "Epoch [1/10], Step [200/469], Loss: 0.3789\n",
            "Epoch [1/10], Step [300/469], Loss: 0.3781\n",
            "Epoch [1/10], Step [400/469], Loss: 0.3513\n",
            "Epoch [2/10], Step [100/469], Loss: 0.2105\n",
            "Epoch [2/10], Step [200/469], Loss: 0.3235\n",
            "Epoch [2/10], Step [300/469], Loss: 0.4068\n",
            "Epoch [2/10], Step [400/469], Loss: 0.3053\n",
            "Epoch [3/10], Step [100/469], Loss: 0.1749\n",
            "Epoch [3/10], Step [200/469], Loss: 0.3380\n",
            "Epoch [3/10], Step [300/469], Loss: 0.2674\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2586\n",
            "Epoch [4/10], Step [100/469], Loss: 0.2581\n",
            "Epoch [4/10], Step [200/469], Loss: 0.1750\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2957\n",
            "Epoch [4/10], Step [400/469], Loss: 0.3441\n",
            "Epoch [5/10], Step [100/469], Loss: 0.3131\n",
            "Epoch [5/10], Step [200/469], Loss: 0.3308\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1583\n",
            "Epoch [5/10], Step [400/469], Loss: 0.4312\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2151\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2176\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2259\n",
            "Epoch [6/10], Step [400/469], Loss: 0.3384\n",
            "Epoch [7/10], Step [100/469], Loss: 0.3289\n",
            "Epoch [7/10], Step [200/469], Loss: 0.2553\n",
            "Epoch [7/10], Step [300/469], Loss: 0.2160\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2232\n",
            "Epoch [8/10], Step [100/469], Loss: 0.3517\n",
            "Epoch [8/10], Step [200/469], Loss: 0.2461\n",
            "Epoch [8/10], Step [300/469], Loss: 0.2002\n",
            "Epoch [8/10], Step [400/469], Loss: 0.2517\n",
            "Epoch [9/10], Step [100/469], Loss: 0.2073\n",
            "Epoch [9/10], Step [200/469], Loss: 0.3053\n",
            "Epoch [9/10], Step [300/469], Loss: 0.2970\n",
            "Epoch [9/10], Step [400/469], Loss: 0.4319\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1299\n",
            "Epoch [10/10], Step [200/469], Loss: 0.2481\n",
            "Epoch [10/10], Step [300/469], Loss: 0.2263\n",
            "Epoch [10/10], Step [400/469], Loss: 0.1602\n",
            "Epoch [11/10], Step [100/469], Loss: 0.2553\n",
            "Epoch [11/10], Step [200/469], Loss: 0.2129\n",
            "Epoch [11/10], Step [300/469], Loss: 0.4304\n",
            "Epoch [11/10], Step [400/469], Loss: 0.2683\n",
            "Epoch [12/10], Step [100/469], Loss: 0.2015\n",
            "Epoch [12/10], Step [200/469], Loss: 0.2190\n",
            "Epoch [12/10], Step [300/469], Loss: 0.2479\n",
            "Epoch [12/10], Step [400/469], Loss: 0.4312\n",
            "Epoch [13/10], Step [100/469], Loss: 0.2818\n",
            "Epoch [13/10], Step [200/469], Loss: 0.2019\n",
            "Epoch [13/10], Step [300/469], Loss: 0.1252\n",
            "Epoch [13/10], Step [400/469], Loss: 0.1554\n",
            "Epoch [14/10], Step [100/469], Loss: 0.1522\n",
            "Epoch [14/10], Step [200/469], Loss: 0.2392\n",
            "Epoch [14/10], Step [300/469], Loss: 0.2919\n",
            "Epoch [14/10], Step [400/469], Loss: 0.2074\n",
            "Epoch [15/10], Step [100/469], Loss: 0.3062\n",
            "Epoch [15/10], Step [200/469], Loss: 0.3589\n",
            "Epoch [15/10], Step [300/469], Loss: 0.1361\n",
            "Epoch [15/10], Step [400/469], Loss: 0.3633\n",
            "Epoch [16/10], Step [100/469], Loss: 0.3766\n",
            "Epoch [16/10], Step [200/469], Loss: 0.3700\n",
            "Epoch [16/10], Step [300/469], Loss: 0.2598\n",
            "Epoch [16/10], Step [400/469], Loss: 0.2179\n",
            "Epoch [17/10], Step [100/469], Loss: 0.2413\n",
            "Epoch [17/10], Step [200/469], Loss: 0.1344\n",
            "Epoch [17/10], Step [300/469], Loss: 0.2518\n",
            "Epoch [17/10], Step [400/469], Loss: 0.2523\n",
            "Epoch [18/10], Step [100/469], Loss: 0.2312\n",
            "Epoch [18/10], Step [200/469], Loss: 0.2781\n",
            "Epoch [18/10], Step [300/469], Loss: 0.3019\n",
            "Epoch [18/10], Step [400/469], Loss: 0.3064\n",
            "Epoch [19/10], Step [100/469], Loss: 0.1585\n",
            "Epoch [19/10], Step [200/469], Loss: 0.2119\n",
            "Epoch [19/10], Step [300/469], Loss: 0.1417\n",
            "Epoch [19/10], Step [400/469], Loss: 0.2964\n",
            "Epoch [20/10], Step [100/469], Loss: 0.2373\n",
            "Epoch [20/10], Step [200/469], Loss: 0.1907\n",
            "Epoch [20/10], Step [300/469], Loss: 0.1801\n",
            "Epoch [20/10], Step [400/469], Loss: 0.2328\n",
            "Epoch [21/10], Step [100/469], Loss: 0.2014\n",
            "Epoch [21/10], Step [200/469], Loss: 0.2271\n",
            "Epoch [21/10], Step [300/469], Loss: 0.1697\n",
            "Epoch [21/10], Step [400/469], Loss: 0.3605\n",
            "Epoch [22/10], Step [100/469], Loss: 0.1865\n",
            "Epoch [22/10], Step [200/469], Loss: 0.2409\n",
            "Epoch [22/10], Step [300/469], Loss: 0.2433\n",
            "Epoch [22/10], Step [400/469], Loss: 0.3549\n",
            "Epoch [23/10], Step [100/469], Loss: 0.2101\n",
            "Epoch [23/10], Step [200/469], Loss: 0.2928\n",
            "Epoch [23/10], Step [300/469], Loss: 0.3200\n",
            "Epoch [23/10], Step [400/469], Loss: 0.3767\n",
            "Epoch [24/10], Step [100/469], Loss: 0.3738\n",
            "Epoch [24/10], Step [200/469], Loss: 0.3359\n",
            "Epoch [24/10], Step [300/469], Loss: 0.1283\n",
            "Epoch [24/10], Step [400/469], Loss: 0.1918\n",
            "Epoch [25/10], Step [100/469], Loss: 0.2593\n",
            "Epoch [25/10], Step [200/469], Loss: 0.1121\n",
            "Epoch [25/10], Step [300/469], Loss: 0.2912\n",
            "Epoch [25/10], Step [400/469], Loss: 0.3784\n",
            "Epoch [26/10], Step [100/469], Loss: 0.1533\n",
            "Epoch [26/10], Step [200/469], Loss: 0.2180\n",
            "Epoch [26/10], Step [300/469], Loss: 0.3998\n",
            "Epoch [26/10], Step [400/469], Loss: 0.2602\n",
            "Epoch [27/10], Step [100/469], Loss: 0.2557\n",
            "Epoch [27/10], Step [200/469], Loss: 0.2344\n",
            "Epoch [27/10], Step [300/469], Loss: 0.2644\n",
            "Epoch [27/10], Step [400/469], Loss: 0.2618\n",
            "Epoch [28/10], Step [100/469], Loss: 0.2769\n",
            "Epoch [28/10], Step [200/469], Loss: 0.3891\n",
            "Epoch [28/10], Step [300/469], Loss: 0.2868\n",
            "Epoch [28/10], Step [400/469], Loss: 0.2517\n",
            "Epoch [29/10], Step [100/469], Loss: 0.1799\n",
            "Epoch [29/10], Step [200/469], Loss: 0.2076\n",
            "Epoch [29/10], Step [300/469], Loss: 0.2358\n",
            "Epoch [29/10], Step [400/469], Loss: 0.2111\n",
            "Epoch [30/10], Step [100/469], Loss: 0.2800\n",
            "Epoch [30/10], Step [200/469], Loss: 0.3390\n",
            "Epoch [30/10], Step [300/469], Loss: 0.1124\n",
            "Epoch [30/10], Step [400/469], Loss: 0.3213\n",
            "Epoch [31/10], Step [100/469], Loss: 0.2117\n",
            "Epoch [31/10], Step [200/469], Loss: 0.2308\n",
            "Epoch [31/10], Step [300/469], Loss: 0.2475\n",
            "Epoch [31/10], Step [400/469], Loss: 0.2031\n",
            "Epoch [32/10], Step [100/469], Loss: 0.2255\n",
            "Epoch [32/10], Step [200/469], Loss: 0.2479\n",
            "Epoch [32/10], Step [300/469], Loss: 0.1858\n",
            "Epoch [32/10], Step [400/469], Loss: 0.1612\n",
            "Epoch [33/10], Step [100/469], Loss: 0.3057\n",
            "Epoch [33/10], Step [200/469], Loss: 0.5228\n",
            "Epoch [33/10], Step [300/469], Loss: 0.2209\n",
            "Epoch [33/10], Step [400/469], Loss: 0.4105\n",
            "Epoch [34/10], Step [100/469], Loss: 0.1851\n",
            "Epoch [34/10], Step [200/469], Loss: 0.2750\n",
            "Epoch [34/10], Step [300/469], Loss: 0.1613\n",
            "Epoch [34/10], Step [400/469], Loss: 0.2944\n",
            "Epoch [35/10], Step [100/469], Loss: 0.2398\n",
            "Epoch [35/10], Step [200/469], Loss: 0.2162\n",
            "Epoch [35/10], Step [300/469], Loss: 0.2364\n",
            "Epoch [35/10], Step [400/469], Loss: 0.1597\n",
            "Epoch [36/10], Step [100/469], Loss: 0.1505\n",
            "Epoch [36/10], Step [200/469], Loss: 0.2709\n",
            "Epoch [36/10], Step [300/469], Loss: 0.2716\n",
            "Epoch [36/10], Step [400/469], Loss: 0.2487\n",
            "Epoch [37/10], Step [100/469], Loss: 0.2538\n",
            "Epoch [37/10], Step [200/469], Loss: 0.1948\n",
            "Epoch [37/10], Step [300/469], Loss: 0.1273\n",
            "Epoch [37/10], Step [400/469], Loss: 0.3069\n",
            "Epoch [38/10], Step [100/469], Loss: 0.1716\n",
            "Epoch [38/10], Step [200/469], Loss: 0.2010\n",
            "Epoch [38/10], Step [300/469], Loss: 0.2565\n",
            "Epoch [38/10], Step [400/469], Loss: 0.1278\n",
            "Epoch [39/10], Step [100/469], Loss: 0.3580\n",
            "Epoch [39/10], Step [200/469], Loss: 0.3046\n",
            "Epoch [39/10], Step [300/469], Loss: 0.2180\n",
            "Epoch [39/10], Step [400/469], Loss: 0.1451\n",
            "Epoch [40/10], Step [100/469], Loss: 0.2079\n",
            "Epoch [40/10], Step [200/469], Loss: 0.2441\n",
            "Epoch [40/10], Step [300/469], Loss: 0.2126\n",
            "Epoch [40/10], Step [400/469], Loss: 0.1801\n",
            "Epoch [41/10], Step [100/469], Loss: 0.1269\n",
            "Epoch [41/10], Step [200/469], Loss: 0.4102\n",
            "Epoch [41/10], Step [300/469], Loss: 0.2640\n",
            "Epoch [41/10], Step [400/469], Loss: 0.2634\n",
            "Epoch [42/10], Step [100/469], Loss: 0.1813\n",
            "Epoch [42/10], Step [200/469], Loss: 0.2504\n",
            "Epoch [42/10], Step [300/469], Loss: 0.2197\n",
            "Epoch [42/10], Step [400/469], Loss: 0.2945\n",
            "Epoch [43/10], Step [100/469], Loss: 0.2326\n",
            "Epoch [43/10], Step [200/469], Loss: 0.3263\n",
            "Epoch [43/10], Step [300/469], Loss: 0.2158\n",
            "Epoch [43/10], Step [400/469], Loss: 0.2842\n",
            "Epoch [44/10], Step [100/469], Loss: 0.1842\n",
            "Epoch [44/10], Step [200/469], Loss: 0.2890\n",
            "Epoch [44/10], Step [300/469], Loss: 0.1312\n",
            "Epoch [44/10], Step [400/469], Loss: 0.1860\n",
            "Epoch [45/10], Step [100/469], Loss: 0.1838\n",
            "Epoch [45/10], Step [200/469], Loss: 0.2247\n",
            "Epoch [45/10], Step [300/469], Loss: 0.2108\n",
            "Epoch [45/10], Step [400/469], Loss: 0.2245\n",
            "Epoch [46/10], Step [100/469], Loss: 0.2079\n",
            "Epoch [46/10], Step [200/469], Loss: 0.2388\n",
            "Epoch [46/10], Step [300/469], Loss: 0.3261\n",
            "Epoch [46/10], Step [400/469], Loss: 0.3340\n",
            "Epoch [47/10], Step [100/469], Loss: 0.1775\n",
            "Epoch [47/10], Step [200/469], Loss: 0.1178\n",
            "Epoch [47/10], Step [300/469], Loss: 0.1828\n",
            "Epoch [47/10], Step [400/469], Loss: 0.2957\n",
            "Epoch [48/10], Step [100/469], Loss: 0.3502\n",
            "Epoch [48/10], Step [200/469], Loss: 0.1865\n",
            "Epoch [48/10], Step [300/469], Loss: 0.2671\n",
            "Epoch [48/10], Step [400/469], Loss: 0.2116\n",
            "Epoch [49/10], Step [100/469], Loss: 0.3666\n",
            "Epoch [49/10], Step [200/469], Loss: 0.1447\n",
            "Epoch [49/10], Step [300/469], Loss: 0.2620\n",
            "Epoch [49/10], Step [400/469], Loss: 0.1809\n",
            "Epoch [50/10], Step [100/469], Loss: 0.1925\n",
            "Epoch [50/10], Step [200/469], Loss: 0.2123\n",
            "Epoch [50/10], Step [300/469], Loss: 0.1656\n",
            "Epoch [50/10], Step [400/469], Loss: 0.2031\n"
          ]
        }
      ],
      "source": [
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(50):\n",
        "  # mini batch for loop\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "        # reshape images to (128, 784) and load to GPU\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda') # labels shape (128)\n",
        "        \n",
        "        # Forward to model\n",
        "        outputs = model(images)\n",
        "        # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward() # automatic gradient calculation (autograd)\n",
        "        optimizer.step() # update model parameter with requires_grad=True \n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFCMbl1Le3QZ"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "owvvmnjxe3QZ",
        "outputId": "e3a445bf-ae47-4347-de24-691090566c51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 92.34 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        # classificatoin model -> get the label prediction of top 1 \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiiEoq8Ye3QZ"
      },
      "source": [
        "### New model: MLP (multi-layer-perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X02cp8v2e3QZ"
      },
      "source": [
        "Previous model used multinomial logistic regression (one linear layer)\\\n",
        "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "idX_BIeLe3Qa"
      },
      "outputs": [],
      "source": [
        "# New model with multi layer\n",
        "# Linear -> Sigmoid -> Linear -> Sigmoid -> Linear\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "      super(NeuralNet, self).__init__()\n",
        "      self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "      self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "      self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hixW-idSe3Qa",
        "outputId": "82fbdd97-93ed-44ec-e2c7-b84de2f76f2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 2.2840\n",
            "Epoch [1/10], Step [200/469], Loss: 1.7887\n",
            "Epoch [1/10], Step [300/469], Loss: 1.2332\n",
            "Epoch [1/10], Step [400/469], Loss: 0.9947\n",
            "Epoch [2/10], Step [100/469], Loss: 0.5507\n",
            "Epoch [2/10], Step [200/469], Loss: 0.4818\n",
            "Epoch [2/10], Step [300/469], Loss: 0.5647\n",
            "Epoch [2/10], Step [400/469], Loss: 0.4883\n",
            "Epoch [3/10], Step [100/469], Loss: 0.3765\n",
            "Epoch [3/10], Step [200/469], Loss: 0.3756\n",
            "Epoch [3/10], Step [300/469], Loss: 0.3558\n",
            "Epoch [3/10], Step [400/469], Loss: 0.3290\n",
            "Epoch [4/10], Step [100/469], Loss: 0.2686\n",
            "Epoch [4/10], Step [200/469], Loss: 0.2944\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2886\n",
            "Epoch [4/10], Step [400/469], Loss: 0.2286\n",
            "Epoch [5/10], Step [100/469], Loss: 0.2221\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2409\n",
            "Epoch [5/10], Step [300/469], Loss: 0.3241\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2258\n",
            "Epoch [6/10], Step [100/469], Loss: 0.1664\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2001\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2272\n",
            "Epoch [6/10], Step [400/469], Loss: 0.1786\n",
            "Epoch [7/10], Step [100/469], Loss: 0.2253\n",
            "Epoch [7/10], Step [200/469], Loss: 0.2243\n",
            "Epoch [7/10], Step [300/469], Loss: 0.1320\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2441\n",
            "Epoch [8/10], Step [100/469], Loss: 0.1548\n",
            "Epoch [8/10], Step [200/469], Loss: 0.1757\n",
            "Epoch [8/10], Step [300/469], Loss: 0.0874\n",
            "Epoch [8/10], Step [400/469], Loss: 0.0869\n",
            "Epoch [9/10], Step [100/469], Loss: 0.1688\n",
            "Epoch [9/10], Step [200/469], Loss: 0.1916\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1706\n",
            "Epoch [9/10], Step [400/469], Loss: 0.1270\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1530\n",
            "Epoch [10/10], Step [200/469], Loss: 0.1699\n",
            "Epoch [10/10], Step [300/469], Loss: 0.2422\n",
            "Epoch [10/10], Step [400/469], Loss: 0.1783\n"
          ]
        }
      ],
      "source": [
        "# Generate model\n",
        "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
        "model = NeuralNet(784, 20, 10)\n",
        "\n",
        "# Upload model to GPU\n",
        "model.cuda()\n",
        "\n",
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer : SGD, lr=0.05, momentum=0.9\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True \n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wDL88X-Re3Qa",
        "outputId": "b75f6cb7-ca76-4ac2-d423-e3169f0e2a93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 95.29 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPoexdwDe3Qa"
      },
      "source": [
        "### Change the following options to obtain better accuracy!! (try it by your-self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLoUbNc6e3Qb"
      },
      "source": [
        "#### (1) Model configurations: \n",
        "- size of hidden layer units\n",
        "- number of layers\n",
        "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
        "\n",
        "#### (2) Optimization configurations\n",
        "- learning rate\n",
        "- epoch\n",
        "- type of optimizer\n",
        "- momentem hyperparameter"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of ai504_03_pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}